{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37f91f6-f123-4cbb-80f8-4cab257b7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import joblib;\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from IPython.display import display_html, clear_output, Markdown;\n",
    "from gc import collect;\n",
    "from os import system, getpid, walk;\n",
    "from psutil import Process;\n",
    "import ctypes;\n",
    "libc = ctypes.CDLL(\"libc.so.6\");\n",
    "\n",
    "from pprint import pprint;\n",
    "from colorama import Fore, Style, init;\n",
    "from warnings import filterwarnings;\n",
    "filterwarnings('ignore');\n",
    "\n",
    "from tqdm.notebook import tqdm;\n",
    "from sklearn.model_selection import KFold as KF\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR;\n",
    "from catboost import CatBoostRegressor as CBR;\n",
    "from sklearn.metrics import mean_absolute_error as mae, make_scorer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018de914-7c77-488e-b67b-397ad41a635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 13.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time   \n",
    "def PrintColor(text:str, color = Fore.BLUE, style = Style.BRIGHT):\n",
    "    print(style + color + text + Style.RESET_ALL); \n",
    "\n",
    "def GetMemUsage():\n",
    "    pid = getpid();\n",
    "    py = Process(pid);\n",
    "    memory_use = py.memory_info()[0] / 2. ** 30;\n",
    "    return f\"RAM memory GB usage = {memory_use :.4}\";\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef5d214-0d31-41d7-b074-b105f91a2be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import set_config; \n",
    "set_config(transform_output = \"pandas\");\n",
    "pd.set_option('display.max_columns', 50);\n",
    "pd.set_option('display.max_rows', 50);\n",
    "\n",
    "print();\n",
    "collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07c46cf-3309-4559-8686-b6690e024380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[34m--> Configuration done!\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    version_nb         = 2;\n",
    "    load_tr_data       = \"Y\";\n",
    "    state              = 22;\n",
    "    LL                 = 'trainV1.pickle';\n",
    "    PI_LL              = 'trainV2.pickle';\n",
    "    path               = f\"./data/\";\n",
    "    mdl_path           = f'./models/';\n",
    "    ftre_imp           = f'./feat_imp/';\n",
    "    methods            = [\"LGBMR\", \"CBR\"];\n",
    "    ML                 = \"Y\";\n",
    "    OPTUNA             = \"N\";\n",
    "    inference          = \"N\";\n",
    "    n_splits           = 5;\n",
    "    n_repeats          = 1;\n",
    "    nbrnd_erly_stp     = 100 ;\n",
    "    mdlcv_mthd         = KF;\n",
    "    spliter            = tts;\n",
    "\n",
    "print();\n",
    "PrintColor(f\"--> Configuration done!\\n\");\n",
    "collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa93182d-8dcf-4b0c-8a93-ceab0249ef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[31m\n",
      "RAM memory GB usage = 0.2032\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def ScoreMetric(ytrue, ypred)-> float:    \n",
    "    return mae(ytrue, ypred);\n",
    "\n",
    "myscorer = make_scorer(ScoreMetric, greater_is_better = False, needs_proba=False,);\n",
    "\n",
    "print();\n",
    "collect();\n",
    "\n",
    "PrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b528dc5-a40c-40ed-a71b-3e7f96b2753b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m---> Version with PI-LL target\u001b[0m\n",
      "\u001b[1m\u001b[31m---> Sampled train shapes = (128, 3), (128, 1)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if (CFG.load_tr_data == \"Y\" or CFG.ML == \"Y\"):\n",
    "    if CFG.version_nb == 1:\n",
    "        df = pd.read_pickle(CFG.path + CFG.LL)\n",
    "        y = df[['target']].dropna()\n",
    "        X = df.drop(['target'], axis=1).dropna()\n",
    "        PrintColor(f\"---> Version with LL target\", color = Fore.GREEN)\n",
    "    else:\n",
    "        df = pd.read_pickle(CFG.path + CFG.PI_LL)\n",
    "        y = df[['target']].dropna()\n",
    "        X = df.drop(['target'], axis=1).dropna()\n",
    "        PrintColor(f\"---> Version with PI-LL target\", color = Fore.GREEN)\n",
    "    PrintColor(f\"---> Sampled train shapes = {X.shape}, {y.shape}\", \n",
    "               color = Fore.RED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad1f9ef-00fd-42a3-a1bf-69f7f650ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.OPTUNA == 'Y':\n",
    "    Xtr, Xdev, ytr, ydev = CFG.spliter(X, y, test_size=0.2, random_state=CFG.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac378cd5-8828-478b-b63b-636d30fc8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.OPTUNA == 'Y':\n",
    "    def objective_cbt(trial, xtrain=Xtr, ytrain=ytr, return_info=False):\n",
    "        cv =  CFG.mdlcv_mthd(n_splits= CFG.n_splits, shuffle = False)\n",
    "\n",
    "        X_train, y_train = Xtr.values, ytr.values\n",
    "        y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "    \n",
    "        collect()\n",
    "\n",
    "        models = []\n",
    "        valid_score = 0\n",
    "    \n",
    "        for train_idx, valid_idx in cv.split(X_train, y_train):\n",
    "        \n",
    "            train_data = X_train[train_idx], y_train[train_idx]\n",
    "            valid_data = X_train[valid_idx], y_train[valid_idx]\n",
    "        \n",
    "        #print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "        \n",
    "            model, y_pred_valid, log = fit_cbt(trial, train_data, valid_data, num_rounds=1000)\n",
    "        \n",
    "            y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "            models.append(model)\n",
    "        \n",
    "            collect()\n",
    "            valid_score += log[\"valid/l1\"]\n",
    "    \n",
    "        valid_score /= len(models)\n",
    "        if return_info:\n",
    "            return valid_score, models, y_pred_valid, y_train\n",
    "        else:\n",
    "            return valid_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0fc4d9-5f33-47c8-b5e4-7f21ce93950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.OPTUNA == 'Y':\n",
    "    def objective_lgb(trial, xtrain=Xtr, ytrain=ytr, return_info=False):\n",
    "        cv =  CFG.mdlcv_mthd(n_splits= CFG.n_splits, shuffle = False)\n",
    "\n",
    "        X_train, y_train = Xtr.values, ytr.values\n",
    "        y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "    \n",
    "        collect()\n",
    "\n",
    "        models = []\n",
    "        valid_score = 0\n",
    "    \n",
    "        for train_idx, valid_idx in cv.split(X_train, y_train):\n",
    "        \n",
    "            train_data = X_train[train_idx], y_train[train_idx]\n",
    "            valid_data = X_train[valid_idx], y_train[valid_idx]\n",
    "        \n",
    "        #print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "        \n",
    "            model, y_pred_valid, log = fit_lgbm(trial, train_data, valid_data, num_rounds=1000)\n",
    "        \n",
    "            y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "            models.append(model)\n",
    "        \n",
    "            collect()\n",
    "            valid_score += log[\"valid/l1\"]\n",
    "    \n",
    "        valid_score /= len(models)\n",
    "        if return_info:\n",
    "            return valid_score, models, y_pred_valid, y_train\n",
    "        else:\n",
    "            return valid_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eaa1476-7be7-4442-b1bd-8286bace3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cbt(trial, train, val, devices=(-1,), seed=None, num_rounds=1500):\n",
    "    X_train, y_train = train\n",
    "    X_valid, y_valid = val\n",
    "    param = {}\n",
    "    param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.001, 0.02, 0.001)\n",
    "    param['depth'] = trial.suggest_int('depth', 2, 16)\n",
    "    param['l2_leaf_reg'] = trial.suggest_loguniform('l2_leaf_reg', 1e-8, 10.0)\n",
    "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
    "    param['grow_policy'] = 'Depthwise'\n",
    "    param['iterations'] = 3000\n",
    "    param['use_best_model'] = True\n",
    "    param['eval_metric'] = 'MAE'\n",
    "    param['od_type'] = 'iter'\n",
    "    param['od_wait'] = 20\n",
    "    param['random_state'] = CFG.state\n",
    "    param['logging_level'] = 'Silent'\n",
    "    device = devices[0]\n",
    "    \n",
    "    if device == -1:\n",
    "        # use cpu\n",
    "        pass\n",
    "    else:\n",
    "        # use gpu\n",
    "        print(f'using gpu device_id {device}...')\n",
    "        params.update({'device': 'gpu', 'gpu_device_id': device})\n",
    "\n",
    "    model = CBR(**param)\n",
    "\n",
    "    model.fit(X_train.copy(), y_train.copy(),\n",
    "                  eval_set=[(X_valid.copy(), y_valid.copy())],\n",
    "                  early_stopping_rounds=CFG.nbrnd_erly_stp)\n",
    "\n",
    "    # predictions\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    \n",
    "    log = {'train/l1': model.get_best_score()['learn']['MAE'],\n",
    "           'valid/l1': model.get_best_score()['validation']['MAE']}\n",
    "    #print(log)\n",
    "    return model, y_pred_valid, log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb78f8c-0d22-445d-9f3c-f5cb8230076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(trial, train, val, devices=(-1,), seed=None, num_rounds=1500):\n",
    "    \"\"\"Train Light GBM model\"\"\"\n",
    "    X_train, y_train = train\n",
    "    X_valid, y_valid = val\n",
    "    metric = 'l1'\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'objective': 'regression',\n",
    "        'learning_rate': 0.1,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        \"bagging_freq\": 5,\n",
    "        \"bagging_fraction\": trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        \"metric\": metric,\n",
    "        'verbose': -1,\n",
    "        'early_stopping': 100\n",
    "        }\n",
    "    device = devices[0]\n",
    "    if device == -1:\n",
    "        # use cpu\n",
    "        pass\n",
    "    else:\n",
    "        # use gpu\n",
    "        print(f'using gpu device_id {device}...')\n",
    "        params.update({'device': 'gpu', 'gpu_device_id': device})\n",
    "\n",
    "    params['seed'] = seed\n",
    "\n",
    "    early_stop = 20\n",
    "    verbose_eval = 20\n",
    "    \n",
    "    d_train = lgb.Dataset(X_train, label=y_train)\n",
    "    d_valid = lgb.Dataset(X_valid, label=y_valid)\n",
    "    watchlist = [d_train, d_valid]\n",
    "\n",
    "    #print('training LGB:')\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist)\n",
    "\n",
    "    # predictions\n",
    "    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    \n",
    "    #print('best_score', model.best_score)\n",
    "    log = {'train/l1': model.best_score['training']['l1'],\n",
    "           'valid/l1': model.best_score['valid_1']['l1']}\n",
    "    return model, y_pred_valid, log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a03b1b9-e2a2-4d68-9050-177658869993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_study(objective):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    PrintColor(f'---> Best Score: {study.best_value}\\n')\n",
    "    PrintColor(f'---> Best params: {study.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd46368-1958-46e9-ae11-f83984bf1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.OPTUNA == 'Y':\n",
    "    optuna_study(objective_cbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f0dfe1-4ef1-4ab4-b0d9-3ecbfc2526d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.ML == \"Y\":\n",
    "    Mdl_Master = {'CBR': CBR(objective='MAE', iterations=3000, verbose=0),\n",
    "                  'LGBMR' : LGBMR(objective='regression_l1', n_estimators=500, verbose=-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "221e7d89-1cdb-418b-b860-0449298a4fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\n"
     ]
    }
   ],
   "source": [
    "if CFG.ML == \"Y\":\n",
    "    methods = CFG.methods;\n",
    "    system('mkdir models');\n",
    "    model_path = CFG.mdl_path;\n",
    "    cv =  CFG.mdlcv_mthd(n_splits= CFG.n_splits, shuffle = True, random_state= CFG.state)\n",
    "    Scores = pd.DataFrame(index = range(CFG.n_splits * CFG.n_repeats),\n",
    "                          columns = methods).fillna(0).astype(np.float32);\n",
    "    \n",
    "    FtreImp = pd.DataFrame(index = X.columns, columns = [methods]).fillna(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef125fcf-3f0b-4700-94ad-f7e26f7d6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "========================= ML Training =========================\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692a146b762340d597b6db98302482f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "<class 'sklearn.model_selection._split.KFold'> CV 5x1: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m-------> Fold0 <-------\u001b[0m\n",
      "\u001b[1m\u001b[35m---> LGBMR   OOF = 5.29686\u001b[0m\n",
      "\u001b[1m\u001b[35m---> CBR     OOF = 5.97626\u001b[0m\n",
      "\u001b[1m\u001b[34m-------> Fold1 <-------\u001b[0m\n",
      "\u001b[1m\u001b[35m---> LGBMR   OOF = 5.84267\u001b[0m\n",
      "\u001b[1m\u001b[35m---> CBR     OOF = 6.10395\u001b[0m\n",
      "\u001b[1m\u001b[34m-------> Fold2 <-------\u001b[0m\n",
      "\u001b[1m\u001b[35m---> LGBMR   OOF = 6.30564\u001b[0m\n",
      "\u001b[1m\u001b[35m---> CBR     OOF = 6.33228\u001b[0m\n",
      "\u001b[1m\u001b[34m-------> Fold3 <-------\u001b[0m\n",
      "\u001b[1m\u001b[35m---> LGBMR   OOF = 7.83914\u001b[0m\n",
      "\u001b[1m\u001b[35m---> CBR     OOF = 6.52155\u001b[0m\n",
      "\u001b[1m\u001b[34m-------> Fold4 <-------\u001b[0m\n",
      "\u001b[1m\u001b[35m---> LGBMR   OOF = 8.23845\u001b[0m\n",
      "\u001b[1m\u001b[35m---> CBR     OOF = 7.99753\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "---> OOF scores across methods <---\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_058d4_row0_col0, #T_058d4_row0_col1, #T_058d4_row1_col1 {\n",
       "  background-color: #fbb4ae;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_058d4_row1_col0, #T_058d4_row2_col1 {\n",
       "  background-color: #b3cde3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_058d4_row2_col0 {\n",
       "  background-color: #decbe4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_058d4_row3_col0 {\n",
       "  background-color: #fddaec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_058d4_row3_col1 {\n",
       "  background-color: #ccebc5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_058d4_row4_col0, #T_058d4_row4_col1 {\n",
       "  background-color: #f2f2f2;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_058d4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_058d4_level0_col0\" class=\"col_heading level0 col0\" >LGBMR</th>\n",
       "      <th id=\"T_058d4_level0_col1\" class=\"col_heading level0 col1\" >CBR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >FoldNb</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_058d4_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_058d4_row0_col0\" class=\"data row0 col0\" >5.29686</td>\n",
       "      <td id=\"T_058d4_row0_col1\" class=\"data row0 col1\" >5.97626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_058d4_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_058d4_row1_col0\" class=\"data row1 col0\" >5.84267</td>\n",
       "      <td id=\"T_058d4_row1_col1\" class=\"data row1 col1\" >6.10395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_058d4_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_058d4_row2_col0\" class=\"data row2 col0\" >6.30564</td>\n",
       "      <td id=\"T_058d4_row2_col1\" class=\"data row2 col1\" >6.33228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_058d4_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_058d4_row3_col0\" class=\"data row3 col0\" >7.83914</td>\n",
       "      <td id=\"T_058d4_row3_col1\" class=\"data row3 col1\" >6.52155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_058d4_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_058d4_row4_col0\" class=\"data row4 col0\" >8.23845</td>\n",
       "      <td id=\"T_058d4_row4_col1\" class=\"data row4 col1\" >7.99753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9fd064a830>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "---> Mean OOF scores across methods <---\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMR    6.704553\n",
       "CBR      6.586314\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.44 s, sys: 467 ms, total: 3.91 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "if CFG.ML == \"Y\":\n",
    "    PrintColor(f\"\\n{'=' * 25} ML Training {'=' * 25}\\n\");\n",
    "    \n",
    "    for fold_nb, (train_idx, dev_idx) in tqdm(enumerate(cv.split(X, y)), \n",
    "                                              f\"{CFG.mdlcv_mthd} CV {CFG.n_splits}x{CFG.n_repeats}\"\n",
    "                                             ):\n",
    "        Xtr  = X.iloc[train_idx];   \n",
    "        Xdev = X.iloc[dev_idx];\n",
    "        ytr  = y.iloc[train_idx];\n",
    "        ydev = y.iloc[dev_idx];\n",
    "        \n",
    "        PrintColor(f\"-------> Fold{fold_nb} <-------\");\n",
    " \n",
    "        for method in methods:\n",
    "            model = Mdl_Master[method];\n",
    "            if method == \"LGBMR\":\n",
    "                model.fit(Xtr, ytr, \n",
    "                          eval_set = [(Xdev, ydev)], \n",
    "                          eval_metric = \"mae\",\n",
    "                          callbacks = [log_evaluation(0,), \n",
    "                                       early_stopping(CFG.nbrnd_erly_stp, verbose = False)], \n",
    "                         );\n",
    "            elif method == \"CBR\":\n",
    "                model.fit(Xtr, ytr, \n",
    "                          eval_set = [(Xdev, ydev)], \n",
    "                          early_stopping_rounds = CFG.nbrnd_erly_stp,\n",
    "                         );\n",
    "                \n",
    "            joblib.dump(model, CFG.mdl_path + f'{method}V{CFG.version_nb}Fold{fold_nb}.model');\n",
    "            \n",
    "            score = ScoreMetric(ydev, model.predict(Xdev));\n",
    "            Scores.at[fold_nb, method] = score;\n",
    "            num_space = 6- len(method);\n",
    "            PrintColor(f\"---> {method} {' '* num_space} OOF = {score:.5f}\", \n",
    "                       color = Fore.MAGENTA);  \n",
    "            del num_space, score;\n",
    "            try:\n",
    "                FtreImp[method] = \\\n",
    "                FtreImp[method].values + (model.feature_importances_ / (CFG.n_splits * CFG.n_repeats));\n",
    "            except:\n",
    "                pass;\n",
    "            \n",
    "            collect();\n",
    "            #clear_output();\n",
    "            \n",
    "    PrintColor(f\"\\n---> OOF scores across methods <---\\n\");\n",
    "    Scores.index.name = \"FoldNb\";\n",
    "    Scores.index = Scores.index + 1;\n",
    "    display(Scores.style.format(precision = 5).\\\n",
    "            background_gradient(cmap = \"Pastel1\")\n",
    "           );\n",
    "    \n",
    "    PrintColor(f\"\\n---> Mean OOF scores across methods <---\\n\");\n",
    "    display(Scores.mean());\n",
    "    \n",
    "    try: FtreImp.to_csv(CFG.ftre_imp + f\"FtreImp_V{CFG.version_nb}.csv\");\n",
    "    except: pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f448cde5-00aa-448b-b375-2784236887c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "---> Trained models\n",
      "\u001b[0m\n",
      "array(['LGBMRV1Fold4', 'LGBMRV2Fold1', 'CBRV2Fold2', 'CBRV2Fold0',\n",
      "       'LGBMRV2Fold2', 'CBRV1Fold0', 'LGBMRV2Fold4', 'CBRV2Fold4',\n",
      "       'LGBMRV1Fold2', 'LGBMRV2Fold3', 'CBRV2Fold1', 'LGBMRV1Fold0',\n",
      "       'CBRV1Fold2', 'CBRV1Fold3', 'LGBMRV1Fold1', 'LGBMRV2Fold0',\n",
      "       'CBRV1Fold1', 'LGBMRV1Fold3', 'CBRV2Fold3', 'CBRV1Fold4'],\n",
      "      dtype='<U12')\n",
      "\n",
      "\u001b[1m\u001b[31m\n",
      "RAM memory GB usage = 0.2368\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mdl_lbl = [];\n",
    "for _, _, filename in walk('./models/'):\n",
    "    mdl_lbl.extend(filename);\n",
    "\n",
    "models = [];\n",
    "for filename in mdl_lbl:\n",
    "    models.append(joblib.load(model_path + f\"{filename}\"));\n",
    "        \n",
    "mdl_lbl    = [m.replace(r\".model\", \"\") for m in mdl_lbl];\n",
    "model_dict = {l:m for l,m in zip(mdl_lbl, models)};\n",
    "PrintColor(f\"\\n---> Trained models\\n\");    \n",
    "pprint(np.array(mdl_lbl), width = 100, indent = 10, depth = 1); \n",
    "\n",
    "print();\n",
    "collect();  \n",
    "libc.malloc_trim(0);\n",
    "PrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eac6304-fe19-4b80-8036-636d04668d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.inference == 'Y':\n",
    "    test_file = None\n",
    "    test = pd.read_pickle(CFG.path + test_file)\n",
    "    sample_prediction = np.mean([model.predict(test) for model in models], 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
